{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NLTK movie_reviews dataset is a well-known text corpus provided by the Natural Language Toolkit (NLTK) that is often used for sentiment analysis and other natural language processing tasks. Hereâ€™s an overview:\n",
    "\n",
    "\n",
    "Collection Size:\n",
    "Contains 2,000 movie reviews in total.\n",
    "\n",
    "Labeling:\n",
    "Reviews are divided equally into two categories: \"pos\" (positive) and \"neg\" (negative), making it ideal for binary sentiment classification tasks.\n",
    "\n",
    "Data Source:\n",
    "The reviews were originally collected from various online movie review sites and have been pre-processed and organized for research purposes.\n",
    "\n",
    "Format:\n",
    "Each review is provided as raw text (a string). In the NLTK corpus, the reviews are accessed via file IDs, and each file belongs to a category (either \"pos\" or \"neg\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.corpus import movie_reviews\n",
    "\n",
    "# Download the movie_reviews corpus if not already available.\n",
    "nltk.download(\"movie_reviews\", quiet=True)\n",
    "\n",
    "# Get the file IDs for positive and negative reviews\n",
    "pos_ids = movie_reviews.fileids(\"pos\")\n",
    "neg_ids = movie_reviews.fileids(\"neg\")\n",
    "\n",
    "# Set a sample size per class (adjust as needed)\n",
    "sample_size = 100\n",
    "\n",
    "# Randomly sample file IDs from both classes\n",
    "sample_pos = random.sample(pos_ids, sample_size)\n",
    "sample_neg = random.sample(neg_ids, sample_size)\n",
    "\n",
    "# Collect the review text and their corresponding labels\n",
    "documents = []\n",
    "labels = []\n",
    "\n",
    "for fileid in sample_pos:\n",
    "    documents.append(movie_reviews.raw(fileid))\n",
    "    labels.append(\"pos\")\n",
    "for fileid in sample_neg:\n",
    "    documents.append(movie_reviews.raw(fileid))\n",
    "    labels.append(\"neg\")\n",
    "\n",
    "# Convert text to a TF-IDF feature matrix\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\", max_features=1000)\n",
    "tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Convert the sparse matrix to a dense array for PCA\n",
    "tfidf_dense = tfidf_matrix.toarray()\n",
    "\n",
    "# Perform PCA to reduce dimensions to 2 for visualization\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(tfidf_dense)\n",
    "\n",
    "# Map labels to colors for visualization: red for positive, blue for negative\n",
    "color_map = {\"pos\": \"red\", \"neg\": \"blue\"}\n",
    "colors = [color_map[label] for label in labels]\n",
    "\n",
    "# Plotting the PCA results\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(pca_result[:, 0], pca_result[:, 1], c=colors, alpha=0.6)\n",
    "\n",
    "# Optionally annotate a few points with their corresponding label\n",
    "for i, (x, y) in enumerate(pca_result):\n",
    "    if i % 15 == 0:  # annotate every 15th point to avoid clutter\n",
    "        plt.annotate(labels[i], (x, y), textcoords=\"offset points\", xytext=(5, 5))\n",
    "\n",
    "plt.xlabel(\"PCA Component 1\")\n",
    "plt.ylabel(\"PCA Component 2\")\n",
    "plt.title(\"PCA of NLTK Movie Reviews (Sampled)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import movie_reviews\n",
    "\n",
    "# Download the movie_reviews corpus if not already available.\n",
    "nltk.download(\"movie_reviews\", quiet=True)\n",
    "\n",
    "# Retrieve file IDs for positive and negative reviews.\n",
    "pos_ids = movie_reviews.fileids(\"pos\")\n",
    "neg_ids = movie_reviews.fileids(\"neg\")\n",
    "\n",
    "# Set the sample size per class.\n",
    "sample_size = 50\n",
    "\n",
    "# Randomly sample file IDs from both classes.\n",
    "sample_pos = random.sample(pos_ids, sample_size)\n",
    "sample_neg = random.sample(neg_ids, sample_size)\n",
    "\n",
    "# Prepare lists to store review text, labels, and hover text (using the first 150 characters).\n",
    "documents = []\n",
    "labels = []\n",
    "hover_text = []\n",
    "\n",
    "for fileid in sample_pos:\n",
    "    review_text = movie_reviews.raw(fileid)\n",
    "    documents.append(review_text)\n",
    "    labels.append(\"pos\")\n",
    "    hover_text.append(review_text[:150].replace(\"\\n\", \" \") + \"...\")\n",
    "    \n",
    "for fileid in sample_neg:\n",
    "    review_text = movie_reviews.raw(fileid)\n",
    "    documents.append(review_text)\n",
    "    labels.append(\"neg\")\n",
    "    hover_text.append(review_text[:150].replace(\"\\n\", \" \") + \"...\")\n",
    "\n",
    "# Convert reviews into a TF-IDF feature matrix.\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\", max_features=1000)\n",
    "tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "tfidf_dense = tfidf_matrix.toarray()\n",
    "\n",
    "# Reduce dimensionality using PCA to two components for visualization.\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(tfidf_dense)\n",
    "\n",
    "# Create a DataFrame to hold the PCA results and related info.\n",
    "results_df = pd.DataFrame({\n",
    "    \"PCA Component 1\": pca_result[:, 0],\n",
    "    \"PCA Component 2\": pca_result[:, 1],\n",
    "    \"Label\": labels,\n",
    "    \"Review Snippet\": hover_text\n",
    "})\n",
    "\n",
    "# Create an interactive scatter plot using Plotly.\n",
    "fig = px.scatter(\n",
    "    results_df,\n",
    "    x=\"PCA Component 1\",\n",
    "    y=\"PCA Component 2\",\n",
    "    color=\"Label\",\n",
    "    hover_data=[\"Review Snippet\"],\n",
    "    title=\"Interactive PCA of NLTK Movie Reviews\"\n",
    ")\n",
    "\n",
    "fig.update_traces(marker=dict(size=10, opacity=0.7))\n",
    "fig.update_layout(xaxis_title=\"PCA Component 1\", yaxis_title=\"PCA Component 2\", hovermode=\"closest\")\n",
    "fig.write_html(\"pca_movie_reviews.html\")\n",
    "fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
